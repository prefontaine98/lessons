{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 1.7: Data Preprocessing\n",
    "\n",
    "### Lesson Duration: 3 hours\n",
    "\n",
    "> Purpose: The purpose of this lesson is to understand the final steps in data preprocessing before fitting the model and testing the accuracy of the model predictions.\n",
    "\n",
    "---\n",
    "\n",
    "### Setup\n",
    "\n",
    "To start this lesson, students should have:\n",
    "\n",
    "- Completed lesson 1.6\n",
    "- All previous Setup\n",
    "- In this lesson we will continue working on the same Jupyter file from the previous lesson\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "After this lesson, students will be able to:\n",
    "\n",
    "- Check assumptions in a linear regression model\n",
    "- Apply data transformations (box-cox and log transformation) on the numerical column\n",
    "- Process numerical data with scaling\n",
    "\n",
    "---\n",
    "\n",
    "### Lesson 1 key concepts\n",
    "\n",
    "> :clock10: 20 min\n",
    "\n",
    "- Review multivariate linear regression model and its assumptions on independent variables\n",
    "- Using EDA to check the assumptions in a linear regression model\n",
    "\n",
    "  - Checking normality assumption (for the residuals)\n",
    "  - Check skewness in the data\n",
    "\n",
    "- Managing skewness in the data\n",
    "\n",
    ":exclamation: Note In this lesson, we will continue working with the same Jupyter file from the previous lesson. If the students do not have the file, use the following code for quick set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./files_for_lesson_and_activities/regression_data1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['HV1'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data['HV1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data['IC1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=data['IC1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iqr = np.percentile(data['IC1'],75) - np.percentile(data['IC1'],25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_limit = np.percentile(data['IC1'],75) + 1.5*iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_limit = np.percentile(data['IC1'],25) - 1.5*iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data['IC1']>lower_limit) & (data['IC1']<upper_limit)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data['IC1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</details>\n",
    "\n",
    "#### :pencil2: Check for Understanding - Class activity/quick quiz\n",
    "\n",
    "> :clock10: 10 min (+ 10 min Review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.07 Activity 1\n",
    "\n",
    "Refer to the `files_for_activities/regression_data1.csv` file. (_The same file used in the class example._)\n",
    "\n",
    "1. Draw a box plot for the IC2.\n",
    "2. Print the descriptive statistics for IC2.\n",
    "3. Remove the outliers from the column IC2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_activity = pd.read_csv('./files_for_lesson_and_activities/regression_data1.csv')\n",
    "data_activity = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "sns.boxplot(x=data_activity['IC2'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "data_activity['IC2'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "iqr = np.percentile(data_activity['IC2'],75) - np.percentile(data_activity['IC2'],25)\n",
    "upper_limit = np.percentile(data_activity['IC2'],75) + 1.5*iqr\n",
    "lower_limit = np.percentile(data_activity['IC2'],25) - 1.5*iqr\n",
    "data_activity = data_activity[(data_activity['IC2'] > lower_limit) & (data_activity['IC2'] < upper_limit)]\n",
    "sns.distplot(data_activity['IC2'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 2 key concepts\n",
    "\n",
    "> :clock10: 20 min\n",
    "\n",
    "- Data transformations:\n",
    "  - Log transformations: to change the scale of a feature ranging from e.g., 0-1000000 (10**6) to 0-6\n",
    "\n",
    "<details>\n",
    "<summary> Click for Code Sample </summary>\n",
    "\n",
    "> Log transformation\n",
    "\n",
    "- Since some values might become -inf when we take the logarithm of values in the column that are 0, we will have to filter those values. Remember we might not able to use this method if there are too many such values and if they are important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to test how the transformation will look like.\n",
    "# Here we are trying two different codes. Notice that in the first function\n",
    "# we are replacing the -inf values after we take logarithm by 0 while in\n",
    "# the second case we will replace them with np.NaN. The idea is that\n",
    "# we will then replace those NaN values in the column with the mean or\n",
    "# median of the column\n",
    "\n",
    "def log_transfom_clean1(x):\n",
    "    x = np.log(x)\n",
    "    if np.isfinite(x):\n",
    "        return x\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HV1_log = list(map(log_transfom_clean1, data['HV1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(HV1_log)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transfom_clean2(x):\n",
    "    x = np.log(x)\n",
    "    if np.isfinite(x):\n",
    "        return x\n",
    "    else:\n",
    "        return np.NAN # We are returning NaNs so that we can replace them with means later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['HV1_log'] = list(map(log_transfom_clean2, data['HV1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we replace the NA by the mean\n",
    "data['HV1_log'] = data['HV1_log'].fillna(np.mean(data['HV1_log']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data['HV1_log'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['HV1'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</details>\n",
    "\n",
    "#### :pencil2: Check for Understanding - Class activity/quick quiz\n",
    "\n",
    "> :clock10: 10 min (+ 10 min Review)\n",
    "\n",
    "<details>\n",
    "  <summary> Click for Instructions: Activity 2 </summary>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.07 Activity 2\n",
    "\n",
    "Keep using the same file.\n",
    "\n",
    "1. Repeat the process(log transformation) for the column IC3. Define the function again yourself.\n",
    "2. Remove the tails of the transformed column to make it closer to the normal distribution. This time change the factor from 1.5 to 3 when calculating the upper limit and the lower limit. Check the distribution plot. Does it remove the tails effectively? If not change the factor back to 1.5 and see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_activity = pd.read_csv('./files_for_lesson_and_activities/regression_data1.csv')\n",
    "data_activity = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "\n",
    "def log_transfom_clean_(x):\n",
    "    x = np.log(x)\n",
    "    if np.isfinite(x):\n",
    "        return x\n",
    "    else:\n",
    "        return np.NAN # We are returning NaNs so that we can replace them with means later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_activity['IC3_log'] = list(map(log_transfom_clean_, data_activity['IC3']))\n",
    "data_activity['IC3_log'] = data_activity['IC3_log'].fillna(np.mean(data_activity['IC3_log']))\n",
    "sns.distplot(data_activity['IC3_log'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(data_activity['IC3_log'], 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "\n",
    "iqr = np.percentile(data_activity['IC3_log'],75) - np.percentile(data_activity['IC3_log'],25)\n",
    "upper_limit = np.percentile(data_activity['IC3_log'], 75) + 1.5*iqr\n",
    "lower_limit = np.percentile(data_activity['IC3_log'], 25) - 1.5*iqr\n",
    "data = data_activity[(data_activity['IC3_log'] > lower_limit) & (data_activity['IC3_log'] < upper_limit)]\n",
    "sns.distplot(data_activity['IC3_log'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 3 key concepts\n",
    "\n",
    "> :clock10: 20 min\n",
    "\n",
    "- Data transformations continued\n",
    "  - Box-cox/power transformations - make the feature closer to a normal distribution. Note that this is not a strict requirement for Linear Regression. Not the data but the residuals need to be normally distributed. Still there are many methods that work better if the data is normally distributed (e.g., hypothesis testing)\n",
    "\n",
    "<details>\n",
    "<summary> Click for Code Sample </summary>\n",
    "\n",
    "- Box-cox transformation\n",
    "\n",
    "The data should be strictly positive to be able to use it in SciPy. We will use it on 'IC1'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since this is median household income, we can filter out negative values:\n",
    "# len(data[data['IC1']<=0])  # number of such observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you do not want to lose this data, replace it with the mean of the column\n",
    "data['IC1_'] = np.where(data['IC1']<=0,0,data['IC1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now calculate mean of the new column , excluding zeros in the count\n",
    "mean = np.sum(data['IC1_']) / len(data[data['IC1_'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['IC1_'] = data['IC1_'].replace(0, mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['IC1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "xt, lmbda = stats.boxcox(data['IC1_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(xt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "#### :pencil2: Check for Understanding - Class activity/quick quiz\n",
    "\n",
    "> :clock10: 10 min (+ 10 min Review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.07 Activity 3\n",
    "\n",
    "Repeat the same steps for column `IC5` for box-cox transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_activity = pd.read_csv('./files_for_lesson_and_activities/regression_data1.csv')\n",
    "data_activity = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the same steps for column 'IC5'\n",
    "# for box cox transformation, we can also use sklearn's preprocessing module. It will be introduced later\n",
    "\n",
    "data_activity['IC5_'] = np.where(data_activity['IC5'] <= 0, 0, data_activity['IC5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.sum(data_activity['IC5_'])/len(data_activity[data_activity['IC5_'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_activity['IC5_'] = data_activity['IC5_'].replace(0, mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_activity = data_activity.drop(['IC5'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt2, lmbda2 = stats.boxcox(data_activity['IC5_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_activity['IC1_transformed'] = xt\n",
    "data_activity['IC5_transformed'] = xt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_activity = data_activity.drop(['IC1_', 'IC5_'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data_activity['TARGET_D']\n",
    "X = data_activity.drop(['TARGET_D'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 4 key concepts\n",
    "\n",
    "> :clock10: 20 min\n",
    "\n",
    "- Why do we need data preprocessing\n",
    "  - make the scales for features similar because methods depend on distances\n",
    "  - make the feature less skewed\n",
    "- Preprocessing data using the `sklearn`: scaling features\n",
    "  - Standardization using MinMaxScaler\n",
    "  - Normalizing using StandardScaler\n",
    "- these are the most common examples of transformations, there are more and we need to choose which ones to apply\n",
    "\n",
    "<details>\n",
    "<summary> Click for Code Sample </summary>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./files_for_lesson_and_activities/regression_data1.csv') # this file is inside files_for_lesson_and_activities folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data['TARGET_D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['TARGET_D'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num = data.select_dtypes(include = np.number)\n",
    "X_cat = data.select_dtypes(include = np.object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling data\n",
    "transformer = MinMaxScaler().fit(X_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_normalized = transformer.transform(X_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_normalized.shape)\n",
    "# pd.DataFrame(x_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing using standard scaler\n",
    "transformer = StandardScaler().fit(X_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_standardized = transformer.transform(X_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_standardized.shape)\n",
    "# pd.DataFrame(x_standardized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### :pencil2: Check for Understanding - Class activity/quick quiz\n",
    "\n",
    "> :clock10: 10 min (+ 10 min Review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.07 Activity 4\n",
    "\n",
    "Keep using the same file (`files_for_activities/regression_data1.csv`) for this exercise.\n",
    "\n",
    "1. Load data `regression_data1.csv`.\n",
    "2. Select 3 numeric columns.\n",
    "3. Plot distributions.\n",
    "4. Normalize.\n",
    "5. Plot new distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "df=pd.read_csv('./files_for_lesson_and_activities/regression_data1.csv') # this file is inside files_for_lesson_and_activities folder\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "data2=df._get_numeric_data().iloc[:, 0:3].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "# same for the three columns\n",
    "\n",
    "for i in range(3):\n",
    "    sns.distplot(data2.iloc[:,i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "transformer = StandardScaler().fit(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_standardized = transformer.transform(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = pd.DataFrame(x_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5\n",
    "sns.distplot(data3.iloc[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### :pencil2: Practice on key concepts - Lab\n",
    "\n",
    "> :clock10: 30 min\n",
    "\n",
    "<details>\n",
    "  <summary> Click for Instructions: Lab </summary>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab | Customer Analysis Round 5\n",
    "\n",
    "For this lab, we still keep using the `marketing_customer_analysis.csv` file that you can find in the `files_for_lab` folder.\n",
    "\n",
    "### Get the data\n",
    "\n",
    "We are using the `marketing_customer_analysis.csv` file.\n",
    "\n",
    "### Dealing with the data\n",
    "\n",
    "Already done in the round 2.\n",
    "\n",
    "### Explore the data\n",
    "\n",
    "Done in the round 3.\n",
    "\n",
    "### Processing Data\n",
    "\n",
    "(_Further processing..._)\n",
    "\n",
    "- X-y split.\n",
    "- Normalize (numerical)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Resources\n",
    "\n",
    "- [Dummy Variable Trap](https://www.jigsawacademy.com/understanding-dummy-variable-traps-regression/)\n",
    "- [Linear regression accuracies](https://www.dataquest.io/blog/understanding-regression-error-metrics/)\n",
    "- [Model accuracies](https://scikit-learn.org/stable/modules/model_evaluation.html)\n",
    "- [Choosing transformations](https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
